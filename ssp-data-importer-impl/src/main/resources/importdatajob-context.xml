<?xml version="1.0" encoding="UTF-8"?>
<!--

    Licensed to Jasig under one or more contributor license
    agreements. See the NOTICE file distributed with this work
    for additional information regarding copyright ownership.
    Jasig licenses this file to you under the Apache License,
    Version 2.0 (the "License"); you may not use this file
    except in compliance with the License. You may obtain a
    copy of the License at:

    http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on
    an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied. See the License for the
    specific language governing permissions and limitations
    under the License.

-->
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:batch="http://www.springframework.org/schema/batch"
       xmlns:p="http://www.springframework.org/schema/p"
       xsi:schemaLocation="
            http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch-2.2.xsd
            http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!-- Database Metadata Repositories  -->
    <bean id="tableMetaDataRepository" class="org.jasig.ssp.util.importer.job.validation.map.metadata.database.JdbcTableColumnMetadataRepository">
        <constructor-arg name="dataSource" ref ="dataSource"/>
        <property name="dateColumnNamePattern" value="${batch.jdbc.date.column.name.pattern}" />
    </bean>

    <bean id="columnMetadataRepository" class="org.jarbframework.constraint.metadata.database.JdbcColumnMetadataRepository">
        <constructor-arg name="dataSource" ref ="dataSource"/>
    </bean>
    <bean id="databaseConstraintRepository" class="org.jasig.ssp.util.importer.job.validation.map.metadata.database.CachingTableColumnMetadataRepository">
        <constructor-arg name="columnMetadataRepository" ref ="tableMetaDataRepository"/>
    </bean>

    <bean id="metadataRepository" class="org.jasig.ssp.util.importer.job.config.MetadataConfigurations" scope="singleton"/>

    <bean id="reportGenerator" class="org.jasig.ssp.util.importer.job.report.ReportGenerator" >
        <property name="batchTitle" value="${batch.title}"/>
        <property name="emailRecipients" value="${batch.email.recipients}"/>
        <property name="replyTo" value="${batch.email.replyTo}"/>
        <property name="sendEmail" value="${batch.sendEmail}" />
        <property name="javaMailSender" ref="javaMailSender"/>
    </bean>

    <!-- Mail Server Configuration -->
    <bean id="javaMailSender" class="org.springframework.mail.javamail.JavaMailSenderImpl">
        <property name="host" value="${batch.smtp.host}" />
        <property name="port" value="${batch.smtp.port}" />
        <property name="protocol" value="${batch.smtp.protocol}" />
        <!-- If MS Exchange does not expect authentication username and password
        must both be null else all connection attempts will fail. Empty strings
        are not sufficient to skip authN -->
        <property name="username" value="${batch.smtp.username}" />
        <property name="password" value="${batch.smtp.password}" />
    </bean>

    <!-- PRE PROCESSING VERIFY INPUT FILE SOAK TIME COPY CONTENTS OF INPUT FOLDER -> PROCESS FOLDER -->
    <bean id="partialUploadGuard" class="org.jasig.ssp.util.importer.job.tasklet.PartialUploadGuard"
                                p:resources="${batch.tables.input.folder}/${batch.files.accepted}"
                                p:directory="${batch.tables.input.folder}"
                                p:lagTimeBeforeStartInMinutes="${batch.tables.lagTimeBeforeStartInMinutes}"
                                p:jobOperator-ref="jobOperator"/>

    <bean id="batchInitializer" class="org.jasig.ssp.util.importer.job.tasklet.BatchInitializer"
                                p:resources="${batch.tables.input.folder}/${batch.files.accepted}"
                                p:duplicateResources="${batch.table.input.duplicate}"
                                p:processDirectory="${batch.tables.process.folder}"
                                p:upsertDirectory="${batch.tables.upsert.folder}"
                                p:metadataRepository-ref="metadataRepository"/>

    <!-- INITIAL PROCESSING OF PROCESS FOLDER COPY CONTENTS OF PROCESS FOLDER -> UPSERT FOLDER  -->
    <bean scope="step" id="rawPartitioner" class="org.springframework.batch.core.partition.support.MultiResourcePartitioner">
        <property name="resources" value="${batch.tables.process.folder}/${batch.files.accepted}"/>
    </bean>

    <bean scope="step" id="singleRawCsvItemReader" class="org.jasig.ssp.util.importer.job.csv.RawItemCsvReader" >
        <property name="resource" value="#{stepExecutionContext[fileName]}"/>
    </bean>

    <bean scope="step" id="rawItemValidateProcessor" class="org.jasig.ssp.util.importer.job.processor.RawItemValidateProcessor" >
        <property name="metadataRepository" ref="metadataRepository" />
    </bean>

    <bean id="rawItemValidateProcessorListener"
      class="org.jasig.ssp.util.importer.job.listener.RawItemValidateProcessorListener">
    </bean>

    <!-- BATCH CLEANUP -->

    <bean id="batchFinaliser" class="org.jasig.ssp.util.importer.job.tasklet.BatchFinalizer"
            p:archiveDirectory="${batch.tables.archive.folder}"
            p:inputDirectory="${batch.tables.input.folder}"
            p:upsertDirectory="${batch.tables.upsert.folder}"
            p:processDirectory="${batch.tables.process.folder}"
            p:batchTitle="${batch.title}"
            p:archiveFiles="${batch.tables.archive}"
            p:retainInputFiles="${batch.table.input.duplicate}"/>


    <bean id="processedRawCsvItemWriter" class="org.jasig.ssp.util.importer.job.csv.RawItemCsvWriter"
          scope="step"
          p:resource="#{stepExecutionContext[fileName]}" >
          <constructor-arg name="writeDirectory" value ="${batch.tables.upsert.folder}"/>
          <property name="appendAllowed" value="true" />
          <property name="lineAggregator">
               <bean class="org.jasig.ssp.util.importer.job.csv.RawItemLineAggregator">
               </bean>
        </property>
         <property name="headerCallback">
            <bean class="org.jasig.ssp.util.importer.job.csv.RawItemFlatFileHeaderCallback">
            </bean>
         </property>
    </bean>

    <!-- FINAL PROCESSING OF UPSERT FOLDER INSERT CONTENTS OF UPSERT FOLDER -> DATABASE  -->
    <bean scope="step" id="singleFilteredCsvItemReader" class="org.jasig.ssp.util.importer.job.csv.RawItemCsvReader" >
        <property name="resource" value="#{stepExecutionContext[fileName]}"/>
    </bean>


    <bean  scope="step" id="compositeTableWriter"
        class="org.springframework.batch.item.support.CompositeItemWriter" >
        <property name="delegates">
             <list>
                 <ref local="stagingTableItemWriter"/>
                 <ref local="externalTableUpsertItemWriter"/>
             </list>
       </property>
    </bean>

    <bean  scope="step" id="partitioner" class="org.springframework.batch.core.partition.support.MultiResourcePartitioner">
        <property name="resources" value="${batch.tables.upsert.folder}/${batch.files.accepted}"/>
    </bean>

    <bean id="processedItemValidateProcessor" class="org.jasig.ssp.util.importer.job.processor.ProcessedItemValidateProcessor"/>

    <bean id="stagingAndUpsertSkipListener" class="org.jasig.ssp.util.importer.job.listener.StagingAndUpsertSkipListener">
            <property name="metadataRepository" ref="metadataRepository" />
    </bean>
     <bean id="stagingAndUpsertListener" class="org.jasig.ssp.util.importer.job.listener.StagingAndUpsertListener"/>
     <bean id="validationSkipListener" class="org.jasig.ssp.util.importer.job.listener.ValidationSkipListener"/>
     <bean id="parsingListener" class="org.jasig.ssp.util.importer.job.listener.ParsingListener"/>
     <bean id="stagingTableTruncator" class="org.jasig.ssp.util.importer.job.listener.StagingTableTruncator"
             p:dataSource-ref="dataSource">
        <property name="truncateExclusions" value="${batch.truncate.exclusions}"></property>
        <property name="metadataRepository" ref="metadataRepository" />
    </bean>

    <bean id="taskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">
        <property name="corePoolSize" value="1"/>
    </bean>

    <bean id="incrementer" class="org.springframework.batch.core.launch.support.RunIdIncrementer" />

    <batch:job id="importJob" restartable="false" incrementer="incrementer">
        <!-- === Start Core Job Step Definition == -->
        <!-- Make sure we don't accidentally process a partial upload -->
        <batch:step id="guardPartialUploads" next="initializeBatch">
            <batch:tasklet ref="partialUploadGuard"></batch:tasklet>
        </batch:step>

        <!-- Another step might be need here if we have to guard against concurrent executions (I think the framework
        takes care of that for us, esp if we're using a db-backed JobRepository.) -->
        <!--<batch:step id="guardConcurrentExecution">-->
        <!--</batch:step>-->

        <!-- Make sure we have a clean working directory, copy new files into it. -->
        <batch:step id="initializeBatch" next="filterRawItems">
            <batch:tasklet ref="batchInitializer"></batch:tasklet>
        </batch:step>

        <!-- Read raw files, map them to validatable beans, validate those beans, write valid records back out
        to another set of files -->
         <batch:step id="filterRawItems" next="stageFilteredItems" >
            <batch:partition step="filterRawItemsSlave" partitioner="rawPartitioner" >
                <batch:handler task-executor="taskExecutor" grid-size="1"/>
            </batch:partition>
        </batch:step>
        <batch:step id="stageFilteredItems"  >
             <batch:partition step="stageFilteredItemsSlave" partitioner="partitioner" >
                <batch:handler task-executor="taskExecutor" grid-size="1"/>
            </batch:partition>
            <batch:listeners>
                <batch:listener ref="stagingTableTruncator"/>
            </batch:listeners>
        </batch:step>
        <!-- Read validated files, write output to staging tables -->

        <!-- === End Core Job Step Definition == -->


        <!-- Use this for custom JobParameter validation, if necessary. Note that you get some simple validation for
        free by using or extending DefaultJobParametersValidator -->
        <!--
         <batch:validator ref="importJobValidator" />
         -->
        <batch:listeners>
              <batch:listener ref="batchFinaliser"/>
             <batch:listener ref="reportGenerator"/>
         </batch:listeners>

    </batch:job>
    <batch:step id="filterRawItemsSlave" >
            <batch:tasklet  >
                <!-- Can add a @skip-limit we can control how many exceptional skips we'll allow before abandoning the
                step. Note that this limit applies separately to reads, processes, and writes. -->
                <batch:chunk reader="singleRawCsvItemReader" processor="rawItemValidateProcessor" writer="processedRawCsvItemWriter"
                             commit-interval="${batch.rawitem.commit.interval}" skip-limit="${batch.rawitem.skip.limit}">

                    <!-- List out exceptions which should result in a record simply being skipped, up to some
                    configurable limit set on the chunk above -->
                    <batch:skippable-exception-classes>
                        <batch:include class="org.postgresql.util.PSQLException"/>
                        <batch:include class="org.springframework.beans.factory.BeanCreationException"/>
                        <batch:include class="org.jasig.ssp.util.importer.job.validation.map.metadata.validation.violation.ViolationException"/>
                        <batch:include class="org.jasig.ssp.util.importer.job.validation.map.metadata.validation.violation.TableViolationException"/>
                    </batch:skippable-exception-classes>

                    <!-- Step-, chunk-, item-read, item-process, item-write, skip-scoped listeners, if needed. -->
                    <batch:listeners>
                        <batch:listener ref="validationSkipListener" />
                        <batch:listener ref="processedRawCsvItemWriter" />
                        <batch:listener ref="parsingListener" />
                        <batch:listener ref="rawItemValidateProcessorListener" />
                    </batch:listeners>
                </batch:chunk>
            </batch:tasklet>
        </batch:step>
    <batch:step id="stageFilteredItemsSlave" >
        <batch:tasklet>
            <!-- Can add a @skip-limit we can control how many exceptional skips we'll allow before abandoning the
            step. Note that this limit applies separately to reads, processes, and writes. -->
            <batch:chunk reader="singleFilteredCsvItemReader" processor="processedItemValidateProcessor" writer="compositeTableWriter"
                     commit-interval="${batch.upsertitem.commit.interval}" skip-limit="${batch.upsertitem.skip.limit}">
                <!-- List out exceptions which should result in a record simply being skipped, up to some
                configurable limit set on the chunk above -->
                <batch:skippable-exception-classes>
                        <batch:include class="java.lang.Exception"/>
                        <batch:exclude class="org.jasig.ssp.util.importer.job.staging.NotSkippableException"/>
                 </batch:skippable-exception-classes>
                <!-- Step-, chunk-, item-read, item-process, item-write, skip-scoped listeners, if needed. -->
                <batch:listeners>
                     <batch:listener ref="stagingTableItemWriter" />
                     <batch:listener ref="externalTableUpsertItemWriter" />
                     <batch:listener ref="stagingAndUpsertSkipListener" />
                     <batch:listener ref="stagingAndUpsertListener" />
                </batch:listeners>
             </batch:chunk>

        </batch:tasklet>

    </batch:step>
</beans>
